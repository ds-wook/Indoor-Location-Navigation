{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "solved-modeling",
   "metadata": {
    "papermill": {
     "duration": 0.012823,
     "end_time": "2021-04-18T17:20:21.647744",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.634921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Disclaimer\n",
    "* Credits go to https://www.kaggle.com/museas for revisiting the cost minimisation solution. \n",
    "* I came across this method from https://www.kaggle.com/mehrankazeminia/1-3-indoor-navigation-cost-minimization-floor, which I thank here for their contribution.\n",
    "* The submission file used was from the best public ensemble, published in this notebook: https://www.kaggle.com/saurabhbagchi/ensembling-best-performing-notebooksCredits go to https://www.kaggle.com/museas for revisiting the cost minimisation solution. I came across this method from https://www.kaggle.com/mehrankazeminia/1-3-indoor-navigation-cost-minimization-floor, which I thank here for their contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-tobago",
   "metadata": {
    "papermill": {
     "duration": 0.011219,
     "end_time": "2021-04-18T17:20:21.670821",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.659602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Solution follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-corrections",
   "metadata": {
    "papermill": {
     "duration": 0.011599,
     "end_time": "2021-04-18T17:20:21.693783",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.682184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "**The step estimation module provided by the host is great, but sometimes it points to strange positions. That of the host uses TYPE_ROTATION_VECTOR. Therefore, by using it in combination with the estimation using TYPE_MAGNETIC_FIELD, the walking direction can be brought closer to the accurate one.**\n",
    "\n",
    "\n",
    "\n",
    "Score improved 0.018 in this sub\n",
    "\n",
    "4.545 →　4.527\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-noise",
   "metadata": {
    "papermill": {
     "duration": 0.011043,
     "end_time": "2021-04-18T17:20:21.716095",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.705052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook demonstrates a post-processing strategy for the\n",
    "[Indoor Location & Navigation](https://www.kaggle.com/c/indoor-location-navigation)\n",
    "competition.\n",
    "\n",
    "To combine machine learning (wifi features) predictions with sensor data (acceleration, attitude heading),\n",
    "I defined cost function as follows,\n",
    "$$\n",
    "L(X_{1:N}) = \\sum_{i=1}^{N} \\alpha_i \\| X_i - \\hat{X}_i \\|^2 + \\sum_{i=1}^{N-1} \\beta_i \\| (X_{i+1} - X_{i}) - \\Delta \\hat{X}_i \\|^2\n",
    "$$\n",
    "where $\\hat{X}_i$ is absolute position predicted by machine learning and $\\Delta \\hat{X}_i$ is relative position predicted by sensor data.\n",
    "\n",
    "Since the cost function is quadratic, the optimal $X$ is solved by linear equation $Q X = c$\n",
    ", where $Q$ and $c$ are derived from above cost function.\n",
    "Because the matrix $Q$ is tridiagonal,\n",
    "each machine learning prediction is corrected by *all* machine learning predictions and sensor data.\n",
    "\n",
    "The optimal hyperparameters ($\\alpha$ and $\\beta$) can be estimated by expected error of machine learning and sensor data,\n",
    "or just tuned by public score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-fever",
   "metadata": {
    "papermill": {
     "duration": 0.01104,
     "end_time": "2021-04-18T17:20:21.738420",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.727380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## References\n",
    "+ [Simple 99% Accurate Floor Model](https://www.kaggle.com/nigelhenry/simple-99-accurate-floor-model)\n",
    "+ [Indoor Location Competition 2.0 (Sample Data and Code)](https://github.com/location-competition/indoor-location-competition-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-night",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-18T17:20:21.778014Z",
     "iopub.status.busy": "2021-04-18T17:20:21.767003Z",
     "iopub.status.idle": "2021-04-18T17:21:22.434050Z",
     "shell.execute_reply": "2021-04-18T17:21:22.433303Z"
    },
    "papermill": {
     "duration": 60.684423,
     "end_time": "2021-04-18T17:21:22.434211",
     "exception": false,
     "start_time": "2021-04-18T17:20:21.749788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'indoor_location_competition_20'...\r\n",
      "remote: Enumerating objects: 1169, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1169/1169), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (1131/1131), done.\u001b[K\r\n",
      "remote: Total 1169 (delta 38), reused 1167 (delta 38), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (1169/1169), 411.37 MiB | 14.06 MiB/s, done.\r\n",
      "Resolving deltas: 100% (38/38), done.\r\n",
      "Checking out files: 100% (1145/1145), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/location-competition/indoor-location-competition-20 indoor_location_competition_20\n",
    "!rm -rf indoor_location_competition_20/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "qualified-candidate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:22.600751Z",
     "iopub.status.busy": "2021-04-18T17:21:22.600110Z",
     "iopub.status.idle": "2021-04-18T17:21:23.534447Z",
     "shell.execute_reply": "2021-04-18T17:21:23.533691Z"
    },
    "papermill": {
     "duration": 1.020349,
     "end_time": "2021-04-18T17:21:23.534595",
     "exception": false,
     "start_time": "2021-04-18T17:21:22.514246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.interpolate\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from indoor_location_competition_20.io_f import read_data_file\n",
    "import indoor_location_competition_20.compute_f as compute_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "devoted-apparel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:23.698644Z",
     "iopub.status.busy": "2021-04-18T17:21:23.698004Z",
     "iopub.status.idle": "2021-04-18T17:21:23.700938Z",
     "shell.execute_reply": "2021-04-18T17:21:23.700424Z"
    },
    "papermill": {
     "duration": 0.086481,
     "end_time": "2021-04-18T17:21:23.701098",
     "exception": false,
     "start_time": "2021-04-18T17:21:23.614617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '../input/indoor-location-navigation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "induced-quality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:23.866813Z",
     "iopub.status.busy": "2021-04-18T17:21:23.866164Z",
     "iopub.status.idle": "2021-04-18T17:21:23.869136Z",
     "shell.execute_reply": "2021-04-18T17:21:23.868622Z"
    },
    "papermill": {
     "duration": 0.087773,
     "end_time": "2021-04-18T17:21:23.869273",
     "exception": false,
     "start_time": "2021-04-18T17:21:23.781500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_rel_positions(acce_datas, ahrs_datas):\n",
    "    step_timestamps, step_indexs, step_acce_max_mins = compute_f.compute_steps(acce_datas)\n",
    "    headings = compute_f.compute_headings(ahrs_datas)\n",
    "    stride_lengths = compute_f.compute_stride_length(step_acce_max_mins)\n",
    "    step_headings = compute_f.compute_step_heading(step_timestamps, headings)\n",
    "    rel_positions = compute_f.compute_rel_positions(stride_lengths, step_headings)\n",
    "    return rel_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loose-hamburg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:24.032850Z",
     "iopub.status.busy": "2021-04-18T17:21:24.032235Z",
     "iopub.status.idle": "2021-04-18T17:21:24.036285Z",
     "shell.execute_reply": "2021-04-18T17:21:24.036829Z"
    },
    "papermill": {
     "duration": 0.087469,
     "end_time": "2021-04-18T17:21:24.036999",
     "exception": false,
     "start_time": "2021-04-18T17:21:23.949530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "order = 6\n",
    "# fs = 50.0  # sample rate, Hz\n",
    "# cutoff = 3\n",
    "\n",
    "fs = 100\n",
    "cutoff = 3.667  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "step_distance = 0.8\n",
    "w_height = 1.7\n",
    "m_trans = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "understood-cabinet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:24.203534Z",
     "iopub.status.busy": "2021-04-18T17:21:24.202897Z",
     "iopub.status.idle": "2021-04-18T17:21:24.208880Z",
     "shell.execute_reply": "2021-04-18T17:21:24.209436Z"
    },
    "papermill": {
     "duration": 0.089261,
     "end_time": "2021-04-18T17:21:24.209605",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.120344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anonymous-aruba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:24.373616Z",
     "iopub.status.busy": "2021-04-18T17:21:24.372980Z",
     "iopub.status.idle": "2021-04-18T17:21:24.379566Z",
     "shell.execute_reply": "2021-04-18T17:21:24.380111Z"
    },
    "papermill": {
     "duration": 0.089539,
     "end_time": "2021-04-18T17:21:24.380285",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.290746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def peak_accel_threshold(data, timestamps, threshold):\n",
    "    d_acc = []\n",
    "    last_state = 'below'\n",
    "    crest_troughs = 0\n",
    "    crossings = []\n",
    "\n",
    "    for i, datum in enumerate(data):\n",
    "        \n",
    "        current_state = last_state\n",
    "        if datum < threshold:\n",
    "            current_state = 'below'\n",
    "        elif datum > threshold:\n",
    "            current_state = 'above'\n",
    "\n",
    "        if current_state is not last_state:\n",
    "            if current_state is 'above':\n",
    "                crossing = [timestamps[i], threshold]\n",
    "                crossings.append(crossing)\n",
    "            else:\n",
    "                crossing = [timestamps[i], threshold]\n",
    "                crossings.append(crossing)\n",
    "\n",
    "            crest_troughs += 1\n",
    "        last_state = current_state\n",
    "    return np.array(crossings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-onion",
   "metadata": {
    "papermill": {
     "duration": 0.084466,
     "end_time": "2021-04-18T17:21:24.546164",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.461698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The blending method is to halve the stride length and adopt all steps, the number of steps will be doubled, but here only the movement distance is required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "practical-prefix",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:24.711553Z",
     "iopub.status.busy": "2021-04-18T17:21:24.710860Z",
     "iopub.status.idle": "2021-04-18T17:21:24.731270Z",
     "shell.execute_reply": "2021-04-18T17:21:24.731738Z"
    },
    "papermill": {
     "duration": 0.105006,
     "end_time": "2021-04-18T17:21:24.731955",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.626949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def steps_compute_rel_positions(sample_file):\n",
    "    \n",
    "    mix_acce = np.sqrt(sample_file.acce[:,1:2]**2 + sample_file.acce[:,2:3]**2 + sample_file.acce[:,3:4]**2)\n",
    "    mix_acce = np.concatenate([sample_file.acce[:,0:1], mix_acce], 1)\n",
    "    mix_df = pd.DataFrame(mix_acce)\n",
    "    mix_df.columns = [\"timestamp\",\"acce\"]\n",
    "    \n",
    "    filtered = butter_lowpass_filter(mix_df[\"acce\"], cutoff, fs, order)\n",
    "\n",
    "    threshold = filtered.mean() * 1.1\n",
    "    crossings = peak_accel_threshold(filtered, mix_df[\"timestamp\"], threshold)\n",
    "\n",
    "    step_sum = len(crossings)/2\n",
    "    distance = w_height * 0.4 * step_sum\n",
    "\n",
    "    mag_df = pd.DataFrame(sample_file.magn)\n",
    "    mag_df.columns = [\"timestamp\",\"x\",\"y\",\"z\"]\n",
    "    \n",
    "    acce_df = pd.DataFrame(sample_file.acce)\n",
    "    acce_df.columns = [\"timestamp\",\"ax\",\"ay\",\"az\"]\n",
    "    \n",
    "    mag_df = pd.merge(mag_df,acce_df,on=\"timestamp\")\n",
    "    mag_df.dropna()\n",
    "    \n",
    "    time_di_list = []\n",
    "\n",
    "    for i in mag_df.iterrows():\n",
    "\n",
    "        gx,gy,gz = i[1][1],i[1][2],i[1][3]\n",
    "        ax,ay,az = i[1][4],i[1][5],i[1][6]\n",
    "\n",
    "        roll = math.atan2(ay,az)\n",
    "        pitch = math.atan2(-1*ax , (ay * math.sin(roll) + az * math.cos(roll)))\n",
    "\n",
    "        q = m_trans - math.degrees(math.atan2(\n",
    "            (gz*math.sin(roll)-gy*math.cos(roll)),(gx*math.cos(pitch) + gy*math.sin(roll)*math.sin(pitch) + gz*math.sin(pitch)*math.cos(roll))\n",
    "        )) -90\n",
    "        if q <= 0:\n",
    "            q += 360\n",
    "        time_di_list.append((i[1][0],q))\n",
    "\n",
    "    d_list = [x[1] for x in time_di_list]\n",
    "    \n",
    "    steps = []\n",
    "    step_time = []\n",
    "    di_dict = dict(time_di_list)\n",
    "\n",
    "    for n,i in enumerate(crossings[:,:1]):\n",
    "        if n % 2 == 1:\n",
    "            continue\n",
    "        direct_now = di_dict[i[0]]\n",
    "        dx = math.sin(math.radians(direct_now))\n",
    "        dy = math.cos(math.radians(direct_now))\n",
    "#         print(int(n/2+1),\"歩目/x:\",dx,\"/y:\",dy,\"/角度：\",direct_now)\n",
    "        steps.append((i[0],dx,dy))\n",
    "        step_time.append(i[0])\n",
    "    \n",
    "        step_dtime = np.diff(step_time)/1000\n",
    "        step_dtime = step_dtime.tolist()\n",
    "        step_dtime.insert(0,5)\n",
    "        \n",
    "        rel_position = []\n",
    "\n",
    "        wp_idx = 0\n",
    "#         print(\"WP:\",round(sample_file.waypoint[0,1],3),round(sample_file.waypoint[0,2],3),sample_file.waypoint[0,0])\n",
    "#         print(\"------------------\")\n",
    "        for p,i in enumerate(steps):\n",
    "            step_distance = 0\n",
    "            if step_dtime[p] >= 1:\n",
    "                step_distance = w_height*0.25\n",
    "            elif step_dtime[p] >= 0.75:\n",
    "                step_distance = w_height*0.3\n",
    "            elif step_dtime[p] >= 0.5:\n",
    "                step_distance = w_height*0.4\n",
    "            elif step_dtime[p] >= 0.35:\n",
    "                step_distance = w_height*0.45\n",
    "            elif step_dtime[p] >= 0.2:\n",
    "                step_distance = w_height*0.5\n",
    "            else:\n",
    "                step_distance = w_height*0.4\n",
    "\n",
    "#             step_x += i[1]*step_distance\n",
    "#             step_y += i[2]*step_distance\n",
    "            \n",
    "            rel_position.append([i[0], i[1]*step_distance, i[2]*step_distance])\n",
    "#     print(rel_position)\n",
    "    \n",
    "    return np.array(rel_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worth-pixel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:24.895663Z",
     "iopub.status.busy": "2021-04-18T17:21:24.895067Z",
     "iopub.status.idle": "2021-04-18T17:21:24.909406Z",
     "shell.execute_reply": "2021-04-18T17:21:24.909927Z"
    },
    "papermill": {
     "duration": 0.097565,
     "end_time": "2021-04-18T17:21:24.910097",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.812532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_path(args):\n",
    "    path, path_df = args\n",
    "    \n",
    "    T_ref  = path_df['timestamp'].values\n",
    "    xy_hat = path_df[['x', 'y']].values\n",
    "    \n",
    "    example = read_data_file(f'{INPUT_PATH}/test/{path}.txt')\n",
    "\n",
    "    rel_positions1 = compute_rel_positions(example.acce, example.ahrs)\n",
    "    rel_positions2 = steps_compute_rel_positions(example)\n",
    "    rel1 = rel_positions1.copy()\n",
    "    rel2 = rel_positions2.copy()\n",
    "    rel1[:,1:] = rel_positions1[:,1:] / 2\n",
    "    rel2[:,1:] = rel_positions2[:,1:] / 2\n",
    "    rel_positions = np.vstack([rel1,rel2])\n",
    "    rel_positions = rel_positions[np.argsort(rel_positions[:, 0])]\n",
    "    \n",
    "    if T_ref[-1] > rel_positions[-1, 0]:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n",
    "    else:\n",
    "        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n",
    "    rel_positions = np.concatenate(rel_positions)\n",
    "    \n",
    "    T_rel = rel_positions[:, 0]\n",
    "    delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n",
    "\n",
    "    N = xy_hat.shape[0]\n",
    "    delta_t = np.diff(T_ref)\n",
    "    alpha = (8.1)**(-2) * np.ones(N)\n",
    "    beta  = (0.3 + 0.3 * 1e-3 * delta_t)**(-2)\n",
    "    A = scipy.sparse.spdiags(alpha, [0], N, N)\n",
    "    B = scipy.sparse.spdiags( beta, [0], N-1, N-1)\n",
    "    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n",
    "\n",
    "    Q = A + (D.T @ B @ D)\n",
    "    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n",
    "    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'site_path_timestamp' : path_df['site_path_timestamp'],\n",
    "        'floor' : path_df['floor'],\n",
    "        'x' : xy_star[:, 0],\n",
    "        'y' : xy_star[:, 1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "empirical-footage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-18T17:21:25.075483Z",
     "iopub.status.busy": "2021-04-18T17:21:25.074833Z",
     "iopub.status.idle": "2021-04-18T17:30:41.955990Z",
     "shell.execute_reply": "2021-04-18T17:30:41.956619Z"
    },
    "papermill": {
     "duration": 556.965177,
     "end_time": "2021-04-18T17:30:41.956835",
     "exception": false,
     "start_time": "2021-04-18T17:21:24.991658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "626it [09:14,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/indoor-loc-and-nav-subs/submission_4475.csv')  # ('../input/simple-99-accurate-floor-model/submission.csv')\n",
    "tmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\n",
    "sub['site'] = tmp[0]\n",
    "sub['path'] = tmp[1]\n",
    "sub['timestamp'] = tmp[2].astype(float)\n",
    "\n",
    "processes = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n",
    "    dfs = tqdm(dfs)\n",
    "    dfs = list(dfs)\n",
    "sub = pd.concat(dfs).sort_values('site_path_timestamp')\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-correlation",
   "metadata": {
    "papermill": {
     "duration": 0.255308,
     "end_time": "2021-04-18T17:30:42.470419",
     "exception": false,
     "start_time": "2021-04-18T17:30:42.215111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 627.581341,
   "end_time": "2021-04-18T17:30:43.361126",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-18T17:20:15.779785",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
